\documentclass[a4paper,10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[spanish,es-tabla]{babel}
\usepackage{authblk}
\usepackage{cite}
\usepackage{framed}
\usepackage{color}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{enumerate}
\usepackage{fullpage}
\usepackage[colorinlistoftodos, textsize=small]{todonotes}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{comment}
\usepackage{tikz}
\tikzstyle{arrow}=[draw, -latex]
\input{tikzlibrarybayesnet.code.tex}
\usepackage{array}    % para que tabular funcione centrado
\usepackage{url}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{cancel}

\graphicspath{ {../../figures/} }

% El paquete authblk no soporta español, no traduce el "and" que separa los autores
\renewcommand\Authand{, y }
\renewcommand\Authands{, y }

\title{Estimaci\'on de habilidad en Go}
\author[a]{Martín Amigo}
\author[a]{Tobías Carreira Munich}
\author[a]{\\ \vspace{0.3cm} \normalsize Directores: Esteban Mocskos y Gustavo Landfried}
% \author[a]{Codirector: Gustavo Landfried}

\date{\today}

\affil[a]{\small Universidad de Buenos Aires. Facultad de Ciencias Exactas y Naturales. Departamento de Computaci\'on. Buenos Aires, Argentina}

\begin{document}

\maketitle

\section*{Metodología}

En este trabajo nos ocupamos de revisar distintos modelos matemático computacionales para estimar la habilidad de jugadores de Go.
Utilizaremos los principales métodos de la bibliografía, teniendo como base el que usa actualmente la Asociación Argentina (AAGo).
Además, propondremos extensiones a uno de los métodos (TrueSkill Through Time) para que contemple tanto el handicap como el komi de cada partida.

\subsection*{Datos}

Trabajamos con el dataset provisto por la AAGo, del cual nos quedamos con las partidas válidas rankeadas. Cuenta con cinco partidas durante el año 2012, y 3313 partidas entre el 27 de junio del 2016 y el 26 de abril del 2020. \todo{Describir un poco más los datos? Cantidad de jugadores, gráficos generales?}

\subsection*{Comparación de modelos}

Al trabajar con distintos modelos, vamos a querer compararlos para saber cual se aproxima mejor a la realidad.
A continuación describiremos la metodolog\'ia bayesiana basada en probabilidad, usando la evidencia de los modelos.
Esta forma introduce un factor que penaliza modelos m\'as complejos de lo necesario, mediante un t\'ermino conocido como Factor de Ockham, que surge naturalmente de las reglas de la probabilidad.
Esto evita sobre ajustes, sin necesidad de acudir a penalizadores ad-hoc.

Inicialmente, vamos a considerar dos niveles de inferencia:

\begin{itemize}
	\item En el primer nivel, asumimos que el modelo con el que trabajamos es el verdadero, y ajustamos nuestro modelo a los datos
	\item En el segundo nivel, tenemos la comparaci\'on de modelos, en la cu\'al usamos la evidencia del primer nivel
\end{itemize}

En el primer nivel, suele haber un espacio de hip\'otesis sobre el cual queremos aprender utilizando los datos.
Por la regla de Bayes:

\begin{equation}\label{eq:bayes-parametros-modelo}
	P(\theta | D, M) = \frac{P(D|\theta, M) P(\theta|M)}{\int P(D|\theta, M) P(\theta|M) dw} = \frac{P(D|\theta, M) P(\theta|M)}{\underbrace{P(D|M)}_{evidencia}}
\end{equation}

donde $\theta$ son las hip\'otesis del modelo, $M$ es el modelo y $D$ son los datos.
Notamos que en la ecuación \ref{eq:bayes-parametros-modelo}, la evidencia es la \textbf{probabilidad de los datos, dado que el modelo $M$ es el verdadero}: $P(D|M)$.

El segundo nivel de inferencia utiliza la evidencia del primer nivel para calcular la probabilidad del modelo, dados los datos:

\begin{equation}\label{eq:bayes-modelos}
	P(M_i | D) = \frac{P(D|M_i) P(M_i)}{\sum_k P(D|M_k) P(M_k)}
\end{equation}

En el caso de que no tengamos informaci\'on previa que nos haga preferir un modelo por sobre el resto, $P(M_i)$ ser\'a equiprobable, por lo que elegir el modelo con mayor probabilidad equivale a quedarse con el modelo de mayor evidencia.
De aqu\'i podemos sacar el concepto de Factor Bayesiano\cite{kass1995-bayesFactors}:

\begin{equation}
	log_b\left(\frac{P(M_i|D)}{P(M_j|D)}\right) = log_b\left(\frac{P(D|M_i) \cancel{P(M_i)}}{P(D|M_j) \cancel{P(M_j)}} \cancel{\frac{\sum_k P(D|M_k) P(M_k)}{\sum_k P(D|M_k) P(M_k)}}\right) = log_b\left(\frac{P(D|M_i)}{P(D|M_j)}\right)
\end{equation}

que resume en un n\'umero (en escala logarítmica\todo{elegir una base y usar la misma en todos lados}) la evidencia provista por los datos a favor de un modelo o teor\'ia por sobre otra.

Por la regla del producto, podemos descomponer la evidencia en la probabilidad de cada dato, dado el modelo y los datos anteriores (ecuación \ref{eq:productoria-evidencia}).
En nuestro contexto, esto se traduce en calcular la probabilidad a priori de cada partida, dado que el método conoce el resultado de las partidas anteriores.
Es destacable el uso de la productoria, ya que una sola partida con probabilidad 0 provoca que la evidencia sea 0.

\begin{equation}\label{eq:productoria-evidencia}
	P(D|M) = \prod P(d_i|M, d_{1}, .., d_{i-1})
\end{equation}

Como la evidencia es un número pequeño y poco interpretable, en múltiples ocasiones usaremos el promedio geométrico de las evidencias individuales de las partidas.

\section*{AGA/AAGo}

La AAGo utiliza el mismo modelo (con pequeñísimas modificaciones) que la AGA, la asociación estadounidense.
Sin entrar en detalles técnicos, este método cuenta siempre con un conjunto de estimaciones que se van actualizando a medida que se cargan torneos.
Para actualizarlas busca cuál es el conjunto de estimaciones más probables a partir de estos resultados (maximiza el likelihood, en términos bayesianos).

\todo{Calculamos las mismas estimaciones y obtuvimos prácticamente lo mismo}

Implementamos nuestro propio software para recorrer las partidas utilizando este algoritmo.
Construimos los archivos de entrada de los torneos a partir de lo registrado en la base de datos, y de las estimaciones previas (cuando las había).
Siguiendo este procedimiento obtuvimos las mismas estimaciones (con diferencias insignificantes) que las de la AAGo.

%\item qué significa calcular evidencia acá en concreto. qué dice el numero y cómo lo calculamos
Para analizar qué tan bueno es este modelo, calculamos su evidencia a partir de los resultados de todos los partidos de la AAGo hasta el [insertar fecha].
\todo{agregar fecha}
Siguiendo lo explicado recientemente, la evidencia del modelo está definida como la productoria de las evidencias individuales de las partidas.
A su vez, estas últimas son la probabilidad de obtener el resultado obtenido asumiendo como ciertas las estimaciones previas. %mal redactado? 'son la probabilidad'

%\item vimos que la evidencia daba muy bajita, casi cero (poner numerito, calcular la online también)
Realizando estos cálculos obtuvimos una evidencia promedio (geométrico) de 0.0032 (es decir, \%0,3).
Es muy baja.
En promedio fue muy poco probable que suceda lo que podíamos esperar que suceda con las estimaciones del modelo.
\todo{agregar evidencia online?}


%\item como se calcula multiplicativamente, podía ser que alguna o algunas partidas estén dando muy bajo y arrastrando error
Como la evidencia es por definición una productoria, pensamos que podría estar sucediendo que alguna de las partidas (o algunas pocas) tenga un error de cargado por el que esté dando un valor de evidencia muy bajo y arrastrando consigo al valor final.
%\item buscamos cuántas partidas daban muy bajo. eran muchas. hicimos un histograma. aparte de muchas altas, hay muchisimas bajas, muchas bajísimas y bastantes muuuy bajisisimas.
Para poner a prueba esta hipótesis, intentamos localizar cuáles eran las partidas que daban muy bajo.
Buscamos cuántas daban menor a 0.0000001 (seis ceros).
Fueron 341.
Considerando que el total de partidas es 3318, es un número muy grande.
Hicimos un histograma para comprender mejor cómo estaban distribuidos estos valores:

\begin{figure}
	\centering
	\includegraphics[scale=0.5]{"../../figures/aago/evidence_histgram.png"}
	\caption{An example graph}
	\label{fig:aago-hist}
\end{figure}

La escala del eje Y es logarítmica, y los valores del eje X corresponden al logaritmo de las evidencias, en base 10. Así, un valor de -70 refiere a una evidencia del orden de $10^{-70}$.
Evidentemente no son pocas las partidas que dan muy baja evidencia, por lo que esa hipótesis queda descartada.

%\item pensamos que quizás eran las partidas iniciales de los jugadores, donde no hay prior. pero las sacamos y no cambiaba mucho (cuantificar esto). tiene sentido que no cambie mucho porque son tipo 100 partidas de 3300
Para intentar explicar la baja evidencia, como segunda hipótesis pensamos que las partidas que estaban dando valores bajos eran las iniciales de cada jugador.
En esa instancia no se tienen estimaciones previas del jugador, y se usa exclusivamente la categoría declarada por el mismo, por lo que podrían ser una fuente de mucho error.
Sin embargo, calculamos nuevamente la evidencia sin tener en cuenta esas partidas y el valor obtenido fue de 0.0037 (contra un 0.0032 con esas partidas incluidas).
Claramente las predicciones iniciales no son malas, o al menos no tienen mucho peso sobre la evidencia final.

%\item nos fijamos la relacion con handicap: claramente es eso. cuando el handicap es bastante alto las predicciones son malísimas. [intentar explicar por qué?]
Estudiando particularmente algunas de las partidas con valores de evidencia más bajos, observamos que se repetía con frecuencia una situación.
Se enfrentaban dos participantes con valores muy dispares, y ganaba el que tenía una estimación previa mucho menor (es decir, el que se estimaba peor jugador).
Tendría sentido que esos resultados sean sorpresivos (es decir, poco evidentes) si no fuera por el hecho de que jugaban con valores altos de handicap.
Procedimos entonces a analizar la relación de la evidencia con el handicap.
A continuación se expone un gráfico de la correlación entre esos dos valores.

\begin{figure}
	\centering
	\includegraphics[scale=0.5]{"../../figures/aago/evidence_hdcap_scatter.png"}
	\caption{An example graph}
	\label{fig:aago-hdcap}
\end{figure}

El eje Y presenta la evidencia en escala logarítmica (base 10) y el eje X el handicap de la partida correspondiente.
Se puede ver que todos los valores muy bajos de evidencia (menores a -20 en escala logarítmica), corresponden a partidas con handicap mayor a 4.
Asimismo, las partidas con handicap mayor a 4 tienen valores más bajos en general.
Además, esta tendencia se manifiesta más cuanto mayor es el handicap.

%\item calcular la evidencia ignorando los handicaps grandes? ( creo que lo puedo hacer en pandas, no hace falta correr de nuevo)
Efectivamente, si calculamos la evidencia promedio sin tener en cuenta a las partidas con handicap mayor a 4 obtenemos 0.34.
Este valor de evidencia, si bien no es muy alto, podría ser aceptable (si no fuera porque requiere ignorar las partidas con handicap).

Lo que aprendemos de este análisis es que este modelo es muy deficiente, particularmente en las partidas que tienen alto valor de handicap.
Evidentemente, le supone al handicap menos influencia de la que efectivamente tiene.
Asumiendo que la AGA tiene una mayor cantidad de miembros, y por tanto menos partidas entre jugadores muy dispares, este defecto podría ser poco significante para esa asociación.
Sin embargo, lo expuesto evidencia %XD
que su repercusión en las estimaciones de la AAGo es sobresaliente.




\section*{Whole History Rating}

Whole-History Rating (WHR) \todo{cita} es un sistema bayesiano de estimación de habilidad.
Aunque en muchos puntos es similar a Elo y al método de AGA, difiere en un punto clave: utiliza la historia completa de partidas para estimar las habilidades de los jugadores, permitiendo que la información vaya no solo del pasado al futuro sino también en dirección contraria.

Cuenta con una implementación abierta, hecha en Python\footnote{Disponible en \url{https://github.com/pfmonville/whole_history_rating}}, la cual usamos para evaluar el modelo.
Permite ingresar el efecto del handicap en cada partida, que es modelada como habilidad adicional (sumada) para el jugador negro.
Decidimos tener como hiperparámetro la habilidad de una piedra de handicap, y asumimos que la habilidad agregada crece de forma lineal con la cantidad de handicap.
El otro hiperparámetro, bastante común en este tipo de modelos, es el factor dinámico.
Tanto WHR como TrueSkill Through Time (el siguiente modelo que estudiamos) modelan el cambio de la habilidad en el tiempo como un proceso de Wiener, que se puede resumir en la ecuación \ref{eq:wiener}.
El factor dinámico $\gamma$ regula el aumento de incertidumbre por cada unidad de tiempo (en nuestro caso, días).
Esto asume que la habilidad puede tanto aumentar como disminuir en el tiempo, y el factor dinámico regula cuanto esperamos que cambie.

\begin{equation}\label{eq:wiener}
	s_{t+k} | s_t \sim N(s_t, k \cdot \gamma)
\end{equation}

Para calcular la evidencia, utilizamos la misma estrategia que el sistema de AGA/AAGo: por cada \textit{batch} de partidas, calculamos la probabilidad a priori de sus resultados dada la información de \textit{batches} anteriores. Después agregamos las partidas al sistema y hacemos correr el método hasta que converge a las habilidades a posteriori.
Para los hiperparámetros, usamos una grilla de valores en un rango que a priori consideramos razonable y calculamos la evidencia con cada uno.\todo{volver a correr con el dataset corregido}.

En la figura \ref{fig:whr-evidence} podemos ver que se alcanza un máximo de $0.547$ de media geométrica. Este máximo se alcanza cuando los hiperparámetros valen: 20 puntos de habilidad (en escala de Elo) por cada piedra de handicap y 6 puntos de habilidad de factor dinámico (en la misma escala).
Como referencia, una diferencia de 20 puntos de habilidad equivale a un $0.528$ de probabilidad de ganar.
Esto nos da un punto de partida superior al modelo original de AGA/AAGo\todo{Bayes factor?}.

\begin{figure}
	\centering
	\includegraphics[scale=0.5]{whr/aago/geometric_mean}
	\caption{Media geométrica de las evidencias a priori de las partidas individuales}
	\label{fig:whr-evidence}
\end{figure}


\section*{TrueSkill Through Time}


% TODO: bibliografia

\end{document}
